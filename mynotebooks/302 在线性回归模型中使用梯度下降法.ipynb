{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 302 在线性回归模型中使用梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "x = np.random.random(size=100)\n",
    "y = x * 3. + 4. + np.random.normal(size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20c6f5e2630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(theta, X_b, y):\n",
    "    try:\n",
    "        return np.sum((y - X_b.dot(theta))**2) / len(X_b)\n",
    "    except:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ(theta, X_b, y):\n",
    "    res = np.empty(len(theta))\n",
    "    res[0] = np.sum(X_b.dot(theta) - y)\n",
    "    for i in range(1, len(theta)):\n",
    "        res[i] = (X_b.dot(theta) - y).dot(X_b[:,i])\n",
    "    return res * 2 / len(X_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_b, y, initial_theta, eta, n_iters = 1e4, epsilon=1e-8):\n",
    "    \n",
    "    theta = initial_theta\n",
    "    cur_iter = 0\n",
    "\n",
    "    while cur_iter < n_iters:\n",
    "        gradient = dJ(theta, X_b, y)\n",
    "        last_theta = theta\n",
    "        theta = theta - eta * gradient\n",
    "        if(abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon):\n",
    "            break\n",
    "            \n",
    "        cur_iter += 1\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.hstack([np.ones((len(x), 1)), x.reshape(-1,1)])\n",
    "initial_theta = np.zeros(X_b.shape[1])\n",
    "eta = 0.01\n",
    "\n",
    "theta = gradient_descent(X_b, y, initial_theta, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.0269033, 3.0043078])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 封装我们的线性回归算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'./code')\n",
    "from playML.LinearRegression import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit_gd(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0043078]\n",
      "4.0269033037832385\n"
     ]
    }
   ],
   "source": [
    "print(lin_reg.coef_)\n",
    "print(lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降的向量化\n",
    "$$\\nabla J(\\theta)=\\frac{2}{m}\\cdot X_b^T \\cdot (X_b \\theta-y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y<50.0]\n",
    "y = y[y<50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'./code')\n",
    "from playML.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8129794056212823"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from playML.LinearRegression import LinearRegression\n",
    "\n",
    "lin_reg1 = LinearRegression()\n",
    "%time lin_reg1.fit_normal(X_train, y_train)\n",
    "lin_reg1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\Anaconda\\Anaconda\\envs\\Kaggle\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "./code\\playML\\LinearRegression.py:32: RuntimeWarning: overflow encountered in square\n",
      "  return np.sum((y - X_b.dot(theta)) ** 2) / len(y)\n",
      "./code\\playML\\LinearRegression.py:55: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if (abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit_gd(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.fit_gd(X_train, y_train, eta=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27586818724477236"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin_reg2.fit_gd(X_train, y_train, eta=0.000001, n_iters=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542932581943915"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法前进行数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 177 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train)\n",
    "X_train_standard = standardScaler.transform(X_train)\n",
    "\n",
    "lin_reg3 = LinearRegression()\n",
    "%time lin_reg3.fit_gd(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129873310487505"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_standard = standardScaler.transform(X_test)\n",
    "lin_reg3.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法的优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "n = 5000\n",
    "\n",
    "big_X = np.random.normal(size=(m, n))\n",
    "\n",
    "true_theta = np.random.uniform(0.0, 100.0, size=n+1)\n",
    "\n",
    "big_y = big_X.dot(true_theta[1:]) + true_theta[0] + np.random.normal(0., 10., size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg1 = LinearRegression()\n",
    "%time big_reg1.fit_normal(big_X, big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_reg2 = LinearRegression()\n",
    "%time big_reg2.fit_gd(big_X, big_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
